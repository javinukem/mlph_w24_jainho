{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Principal Component Analysis\n",
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement PCA (fill in the blanks in the function below)\n",
    "\n",
    "def pca(data, n_components=None):\n",
    "    \"\"\"\n",
    "    Principal Component Analysis on a p x N data matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Data matrix of shape (p, N).\n",
    "    n_components : int, optional\n",
    "        Number of requested components. By default returns all components.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray, np.ndarray\n",
    "        the pca components (shape (n_components, p)) and the projection (shape (n_components, N))\n",
    "\n",
    "    \"\"\"\n",
    "    # set n_components to p by default\n",
    "    n_components = data.shape[0] if n_components is None else n_components\n",
    "    assert n_components <= data.shape[0], f\"Got n_components larger than dimensionality of data!\"\n",
    "    \n",
    "    N = data.shape[1]\n",
    "    # center the data\n",
    "    centered_data = np.matmul(data,(np.identity(N)-(1/N)*(np.zeros(N)+1)))\n",
    "    # compute X times X transpose\n",
    "    xx =np.matmul(centered_data,centered_data.T)\n",
    "    # compute the eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(xx)\n",
    "    # sort the eigenvectors by eigenvalue and take the n_components largest ones\n",
    "    sorted_indices = eigenvalues.argsort()[::-1]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    #print(np.shape(np.dot(np.array([eigenvectors[0]]).T,np.array([eigenvectors[0]]))))\n",
    "    # compute X_projected, the projection of the data to the components\n",
    "    W = eigenvectors[:, :n_components]\n",
    "\n",
    "    X_projected = np.matmul(W.T, centered_data)\n",
    "\n",
    "    return eigenvectors[:n_components], X_projected  # return the n_components first components and the pca projection of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.00000238 17.99999928  1.99999988]\n",
      "[[ 4.04768776e-18 -7.74843179e-17  0.00000000e+00]\n",
      " [ 5.33619148e-17  0.00000000e+00  0.00000000e+00]]\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Projections not matching",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(projection, np\u001b[38;5;241m.\u001b[39mndarray), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected projection to be numpy array but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(projection)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m projection\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (n_components, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncorrect shape of projection: Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n_components,\u001b[38;5;250m \u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprojection\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(projection, true_projection \u001b[38;5;241m*\u001b[39m (components \u001b[38;5;241m*\u001b[39m true_components)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjections not matching\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest successful!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Projections not matching"
     ]
    }
   ],
   "source": [
    "# Example data to test your implementation \n",
    "# All the asserts on the bottom should go through if your implementation is correct\n",
    "\n",
    "data = np.array([\n",
    "    [ 1,  0,  0, -1,  0,  0],\n",
    "    [ 0,  3,  0,  0, -3,  0],\n",
    "    [ 0,  0,  5,  0,  0, -5]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# add a random offset to all samples. it should not affect the results\n",
    "data += np.random.randn(data.shape[0], 1)\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "components, projection = pca(data, n_components=n_components)  # apply your implementation\n",
    "\n",
    "# the correct results are known (up to some signs)\n",
    "true_components = np.array([[0, 0, 1], [0, 1, 0]], dtype=np.float32)\n",
    "true_projection = np.array([\n",
    "    [ 0,  0,  5,  0,  0, -5],\n",
    "    [ 0,  3,  0,  0, -3,  0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(components-true_components)\n",
    "\n",
    "print(projection-projection)\n",
    "\n",
    "# check that components match, up to sign\n",
    "assert isinstance(components, np.ndarray), f'Expected components to be numpy array but got {type(components)}'\n",
    "assert components.shape == true_components.shape, f'{components.shape}!={true_components.shape}'\n",
    "assert np.allclose(np.abs(components * true_components).sum(1), np.ones(n_components)), f'Components not matching'\n",
    "\n",
    "# check that projections agree, taking into account potentially flipped components\n",
    "assert isinstance(projection, np.ndarray), f'Expected projection to be numpy array but got {type(projection)}'\n",
    "assert projection.shape == (n_components, data.shape[1]), f'Incorrect shape of projection: Expected {(n_components, data.shape[1])}, got {projection.shape}'\n",
    "assert np.allclose(projection, true_projection * (components * true_components).sum(1, keepdims=True), atol=1e-6), f'Projections not matching'\n",
    "\n",
    "print('Test successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data (it is a subset of the data at https://opendata.cern.ch/record/4910#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('data/dijet_features.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "label_names = ['b', 'c', 'q']  # bottom, charm or light quarks\n",
    "\n",
    "print(f'{features.shape=}, {labels.shape=}')  # print the shapes\n",
    "\n",
    "# TODO: print how many samples of each class are present in the data (hint: numpy.unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: report range of features and normalize the data to zero mean and unit variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "Compute a 2D PCA projection and make a scatterplot of the result, once without color, once coloring the dots by label. Interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply PCA as implemented in (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot of the PCA projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot, coloring the dots by their label and including a legend with the label names\n",
    "# (hint: one way is to call plt.scatter once for each of the three possible labels. Why could it be problematic to scatter the data sorted by labels though?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nonlinear Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap  # import umap-learn, see https://umap-learn.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not done 1(b) yet, you can load the normalized features directly:\n",
    "features = np.load('data/dijet_features_normalized.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "label_names = ['b', 'c', 'q']  # bottom, charm or light quarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply umap on the normalized jet features from excercise 1. It will take a couple of seconds.\n",
    "# note: umap uses a different convention regarding the feature- and sample dimension, N x p instead of p x N!\n",
    "\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a scatterplot of the UMAP projection\n",
    "\n",
    "# TODO: make a scatterplot, coloring the dots by their label and including a legend with the label names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors in (2, 4, 8, 15, 30, 60, 100):\n",
    "    # TODO: repeat the above, varying the n_neighbors parameter of UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlph_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
